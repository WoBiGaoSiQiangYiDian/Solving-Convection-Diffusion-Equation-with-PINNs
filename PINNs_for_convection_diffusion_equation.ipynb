{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor, Parameter, context\n",
    "from mindspore.common.initializer import initializer, HeUniform, Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set MindSpore context\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network for PINNs\n",
    "class NN(nn.Cell):\n",
    "    def __init__(self, input_size, hidden_size, output_size, depth, act=nn.Tanh):\n",
    "        super(NN, self).__init__()\n",
    "        layers = []\n",
    "        # Input layer\n",
    "        layers.append(nn.Dense(input_size, hidden_size, weight_init=HeUniform()))\n",
    "        layers.append(act())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Dense(hidden_size, hidden_size, weight_init=HeUniform()))\n",
    "            layers.append(act())\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Dense(hidden_size, output_size, weight_init=Uniform(scale=0.1)))\n",
    "        \n",
    "        self.net = nn.SequentialCell(layers)\n",
    "    \n",
    "    def construct(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, convection_coeff=0.5, diffusion_coeff=0.01):\n",
    "        self.device = context.get_context(\"device_target\")\n",
    "        self.loss_history = []\n",
    "        self.epoch_history = []\n",
    "        \n",
    "        self.model = NN(\n",
    "            input_size=2,\n",
    "            hidden_size=20,\n",
    "            output_size=1,\n",
    "            depth=4,\n",
    "            act=nn.Tanh\n",
    "        )\n",
    "        \n",
    "        # Define the spatial and temporal domain\n",
    "        self.x_min, self.x_max = 0.0, 1.0\n",
    "        self.t_min, self.t_max = 0.0, 1.0\n",
    "        \n",
    "        # Define convection and diffusion coefficients\n",
    "        self.c = convection_coeff\n",
    "        self.D = diffusion_coeff\n",
    "        \n",
    "        # Visualization grid\n",
    "        self.h_vis = 0.01\n",
    "        self.k_vis = 0.01\n",
    "        x_vis = np.arange(self.x_min, self.x_max + self.h_vis, self.h_vis)\n",
    "        t_vis = np.arange(self.t_min, self.t_max + self.k_vis, self.k_vis)\n",
    "        \n",
    "        # setting up the PDE points for training\n",
    "        x_train_pde_res = np.linspace(self.x_min, self.x_max, 100)\n",
    "        t_train_pde_res = np.linspace(self.t_min, self.t_max, 100)\n",
    "        pde_points_x, pde_points_t = np.meshgrid(x_train_pde_res, t_train_pde_res, indexing='ij')\n",
    "        self.pde_points = np.stack([pde_points_x.flatten(), pde_points_t.flatten()], axis=1)\n",
    "        self.pde_points = Tensor(self.pde_points, mindspore.float32)\n",
    "        self.pde_points.requires_grad = True\n",
    "        \n",
    "        # Training data\n",
    "        x_bc_res = np.linspace(self.x_min, self.x_max, 50)\n",
    "        t_bc_res = np.linspace(self.t_min, self.t_max, 50)\n",
    "        \n",
    "        # Boundary conditions\n",
    "        bc1 = np.stack(np.meshgrid([self.x_min], t_bc_res, indexing='ij')).reshape(2, -1).T\n",
    "        bc2 = np.stack(np.meshgrid([self.x_max], t_bc_res, indexing='ij')).reshape(2, -1).T\n",
    "        ic = np.stack(np.meshgrid(x_bc_res, [self.t_min], indexing='ij')).reshape(2, -1).T\n",
    "        \n",
    "        self.X_train = np.concatenate([bc1, bc2, ic])\n",
    "        self.X_train = Tensor(self.X_train, mindspore.float32)\n",
    "        \n",
    "        # Boundary and initial conditions\n",
    "        y_bc1 = np.ones(len(bc1))  # LBC\n",
    "        y_bc2 = np.zeros(len(bc2))  # RBC\n",
    "        y_ic = np.exp(-10 * ic[:, 0]**2)  # IC\n",
    "        \n",
    "        self.y_train = np.concatenate([y_bc1, y_bc2, y_ic])\n",
    "        self.y_train = Tensor(self.y_train.reshape(-1, 1), mindspore.float32)\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.iter = 1\n",
    "        \n",
    "        # Adam\n",
    "        self.optimizer = nn.Adam(self.model.trainable_params(), learning_rate=1e-3)\n",
    "        \n",
    "        # visualization grid\n",
    "        self.plot_x = x_vis\n",
    "        self.plot_t = t_vis\n",
    "        self.plot_X, self.plot_T = np.meshgrid(self.plot_x, self.plot_t)\n",
    "        self.plot_points = np.vstack([self.plot_X.ravel(), self.plot_T.ravel()]).T\n",
    "        self.plot_points = Tensor(self.plot_points, mindspore.float32)\n",
    "    \n",
    "    # PDE Loss\n",
    "    def pde_loss(self, x_pde):\n",
    "        u = self.model(x_pde)\n",
    "        grad_fn = mindspore.ops.grad(self.model, grad_position=0)\n",
    "        grads = grad_fn(x_pde)\n",
    "        u_x = grads[:, 0:1]\n",
    "        u_t = grads[:, 1:2]\n",
    "        \n",
    "        # second derivative\n",
    "        grad2_fn = mindspore.ops.grad(lambda x: grad_fn(x)[:, 0:1].sum(), grad_position=0)\n",
    "        u_xx = grad2_fn(x_pde)[:, 0:1]\n",
    "        \n",
    "        f_pde = u_t + self.c * u_x - self.D * u_xx\n",
    "        return self.criterion(f_pde, ops.ZerosLike()(f_pde))\n",
    "    \n",
    "    # Train step\n",
    "    def train_step(self, epochs):\n",
    "        # Forward pass\n",
    "        def forward_fn(x, y, pde_points):\n",
    "            pred_data = self.model(x)\n",
    "            loss_data = self.criterion(pred_data, y)\n",
    "            loss_pde = self.pde_loss(pde_points)\n",
    "            total_loss = loss_data + loss_pde\n",
    "            return total_loss, loss_data, loss_pde\n",
    "        \n",
    "        # Gradient function\n",
    "        grad_fn = mindspore.value_and_grad(forward_fn, None, self.optimizer.parameters, has_aux=True)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            # compute gradients and loss\n",
    "            (total_loss, loss_data, loss_pde), grads = grad_fn(\n",
    "                self.X_train, self.y_train, self.pde_points\n",
    "            )\n",
    "            \n",
    "            # update parameters\n",
    "            self.optimizer(grads)\n",
    "            \n",
    "            # Loss\n",
    "            self.loss_history.append(total_loss.item())\n",
    "            self.epoch_history.append(self.iter)\n",
    "            \n",
    "            if self.iter % 100 == 0:\n",
    "                print(f\"Iter {self.iter}, Total Loss: {total_loss.item():.4e}, \"\n",
    "                      f\"Data Loss: {loss_data.item():.4e}, PDE Loss: {loss_pde.item():.4e}\")\n",
    "            self.iter += 1\n",
    "    \n",
    "    # Train\n",
    "    def train(self, epochs_adam=8000):\n",
    "        print(\"Starting Adam training...\")\n",
    "        self.model.set_train()\n",
    "        self.train_step(epochs_adam)\n",
    "        print(\"Training complete.\")\n",
    "    \n",
    "    # Visualization\n",
    "    def plot_results(self):\n",
    "        self.model.set_train(False)\n",
    "        u_pred = self.model(self.plot_points).asnumpy().reshape(self.plot_T.shape)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        times_to_plot = [0.0, 0.1, 0.25, 0.5, 0.75, 1.0] \n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(times_to_plot))) \n",
    "\n",
    "        for i, t_val in enumerate(times_to_plot):\n",
    "            t_idx = np.argmin(np.abs(self.plot_t - t_val)) \n",
    "            plt.plot(self.plot_x, u_pred[t_idx, :], label=f'PINN Pred. at t={t_val:.2f}', color=colors[i])\n",
    "        \n",
    "        # draw initial condition points\n",
    "        ic_train_mask = (self.X_train[:, 1] == self.t_min)\n",
    "        ic_x_train = self.X_train[ic_train_mask, 0].asnumpy()\n",
    "        ic_y_train = self.y_train[ic_train_mask].asnumpy().flatten()\n",
    "        plt.scatter(ic_x_train, ic_y_train, color='red', marker='o', s=30, label='IC Training Data', zorder=5)\n",
    "\n",
    "        # draw boundary condition points\n",
    "        bc_left_mask = (self.X_train[:, 0] == self.x_min)\n",
    "        bc_right_mask = (self.X_train[:, 0] == self.x_max)\n",
    "        \n",
    "        bc_x_left_train = self.X_train[bc_left_mask, 0].asnumpy()\n",
    "        bc_y_left_train = self.y_train[bc_left_mask].asnumpy().flatten()\n",
    "        plt.scatter(bc_x_left_train, bc_y_left_train, color='green', marker='x', s=30, label=f'BC Training Data (x={self.x_min})', zorder=5)\n",
    "\n",
    "        bc_x_right_train = self.X_train[bc_right_mask, 0].asnumpy()\n",
    "        bc_y_right_train = self.y_train[bc_right_mask].asnumpy().flatten()\n",
    "        plt.scatter(bc_x_right_train, bc_y_right_train, color='blue', marker='x', s=30, label=f'BC Training Data (x={self.x_max})', zorder=5)\n",
    "\n",
    "        plt.title('PINN Predicted Solution $u(x,t)$ at Different Time Snapshots')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('u')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        x_to_plot = [0.0, 0.25, 0.5, 0.75, 1.0] \n",
    "        colors = plt.cm.plasma(np.linspace(0, 1, len(x_to_plot)))\n",
    "\n",
    "        for i, x_val in enumerate(x_to_plot):\n",
    "            x_idx = np.argmin(np.abs(self.plot_x - x_val)) \n",
    "            plt.plot(self.plot_t, u_pred[:, x_idx], label=f'PINN Pred. at x={x_val:.2f}', color=colors[i])\n",
    "        \n",
    "        plt.title('PINN Predicted Solution $u(x,t)$ at Different Spatial Locations Over Time')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('u')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # heatmap/contour plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.contourf(self.plot_X, self.plot_T, u_pred, 50, cmap='viridis')\n",
    "        cbar = plt.colorbar(label='u(x,t)')\n",
    "        \n",
    "        # draw training data points\n",
    "        X_train_np = self.X_train.asnumpy()\n",
    "        plt.scatter(X_train_np[:, 0], X_train_np[:, 1], color='red', marker='o', s=10, label='Training Data Points', alpha=0.5)\n",
    "\n",
    "        plt.title('PINN Predicted Solution $u(x,t)$ (Heatmap)')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('t')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 3D surface plot\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        surf = ax.plot_surface(self.plot_X, self.plot_T, u_pred, cmap=cm.viridis,\n",
    "                               linewidth=0, antialiased=False)\n",
    "        fig.colorbar(surf, shrink=0.5, aspect=5, label='u(x,t)')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('t')\n",
    "        ax.set_zlabel('u')\n",
    "        ax.set_title('PINN Predicted Solution $u(x,t)$ (3D Surface)')\n",
    "        plt.show()\n",
    "        \n",
    "        # Loss History Plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(self.epoch_history, self.loss_history)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Total Loss (Log Scale)')\n",
    "        plt.title('PINN Training Loss History')\n",
    "        plt.yscale('log') \n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    convection_speed = 0.5\n",
    "    diffusion_coeff = 0.01\n",
    "    \n",
    "    pinn_solver = Net(convection_coeff=convection_speed, diffusion_coeff=diffusion_coeff)\n",
    "    \n",
    "    print(\"Starting PINN training...\")\n",
    "    pinn_solver.train(epochs_adam=8000)\n",
    "    print(\"Training complete. Generating plots...\")\n",
    "    \n",
    "    pinn_solver.plot_results()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
